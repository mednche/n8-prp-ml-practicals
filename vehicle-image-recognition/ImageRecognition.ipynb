{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image recognition of vehicle's make (and model) using TensorFlow\n",
    "\n",
    "**Credits**: This code was produced by [Natacha Chenevoy](https://github.com/mednche) and is available on [Github](https://github.com/mednche/Vehicle-Image-Recognition). I ([Nick Malleson](http://nickmalleson.co.uk/)) have adapted it slightly here, but have made only relatively minor changes so can't take any of the credit. For full details about the original project, the data, etc., refer to Natacha's page.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This script trains a convolutional neural network model to recognise a vehicle's make and model. This was done using Google's [Tensorflow](https://www.tensorflow.org/) and [TFlearn](http://tflearn.org/), a deep learning library built on top of Tensorflow. \n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset, which is available as part of a machine learning competition on [Kaggle](https://www.kaggle.com/c/carvana-image-masking-challenge/data) contains a large number of photographs of cars. There is also a separate file that tells us the make and model of each car. The challenge is to create an algorithm that will automatically work out the make and model from new images. \n",
    "\n",
    "**IMPORTANT**: Together, the pictures files are very big. Therefore you have to _**download the images yourself**_ before the code below will work:\n",
    "\n",
    " 1. [This page](https://www.kaggle.com/c/carvana-image-masking-challenge/data) lists all of the data files that are available for the competition. You need to download `train.zip`, extract the images, and store them in the `CarImages` folder\n",
    " 2. If you want more images (which will make the model take longer to train, but might lead to better results) then also download `test.zip`. Again, extract those images and put them in the `CarImages` folder.\n",
    "\n",
    "## Training the network\n",
    "\n",
    "I have trained two models with the same architecture (see below). \n",
    "- Model 1 takes make, model and vehicle ID in input\n",
    "- Model 2 only takes make and model in input\n",
    "\n",
    "\n",
    "**Architecture of the neural network:**\n",
    "\n",
    "Input -> Conv -> Relu -> Pool -> Conv -> Relu -> Pool -> FullyConnected -> Regression\n",
    "\n",
    "This architecture is rather commonly used in deep learning.\n",
    "\n",
    "**Neural network terminology:**\n",
    "- *One epoch* = one forward pass and one backward pass of all the training images\n",
    "- *Batch size* = the number of training images in one forward/backward pass. The higher the batch size, the more memory space needed, but it will be faster.\n",
    "- *Number of iterations* = number of passes, each pass using [batch size] number of images. \n",
    "To be clear, one pass = one forward pass + one backward pass (the forward pass and backward pass are not counted as two different passes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries\n",
    "\n",
    "We are going to use a library called [Tensor Flow](https://www.tensorflow.org/). This is an \"an open source software library for numerical computation using data flow graphs\". It is commonly used to do image recognition tasks (among other things).\n",
    "\n",
    "You need to install the following libraries:\n",
    " - `conda install tensorflow scikit-learn pillow imageio`\n",
    " - `pip install tflearn`\n",
    " \n",
    " \n",
    "You also need `pandas` and `numpy` but may have these already as we installed them in the previous tutorial. Just in case not, you can install them both by installing `scipy`:\n",
    " - `conda install scipy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from os.path import splitext\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# tflearn and some helpers\n",
    "import tflearn\n",
    "from tflearn.data_utils import shuffle\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "\n",
    "# for reading images\n",
    "import imageio\n",
    "from PIL import Image\n",
    "\n",
    "# Displaying things (graphs etc) \n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Get name of all images in folder\n",
    "\n",
    "Open the folder with the images and get the name of every image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all files in merged folder\n",
    "folder = \"./CarImages\"\n",
    "onlyfiles = []\n",
    "for f in os.listdir(folder):\n",
    "    if os.path.isfile(os.path.join(folder, f)) and \\\n",
    "      os.path.join(folder, f)[-4:] == \".jpg\":\n",
    "        onlyfiles.append(f)\n",
    "print(\"Working with\",len(onlyfiles),\"images\")\n",
    "\n",
    "# due to low memory available, I restricted the dataset size\n",
    "#onlyfiles = onlyfiles[:5000]\n",
    "#print(\"Reduced to {0} images\".format(len(onlyfiles)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the labels associated with each images\n",
    "\n",
    "There is a file called `metadata.csv` that stores the make and model of each car. The code below reads this file and cross-references it with the name of the image file to work out which car is in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_files = []\n",
    "y_train =  pd.DataFrame()\n",
    "\n",
    "# import the metadata for the cars\n",
    "data =  pd.read_csv(\"./CarImages/metadata.csv\")\n",
    "\n",
    "for _file in onlyfiles:\n",
    "    # add file name to list of train_file\n",
    "    train_files.append(_file)\n",
    "    \n",
    "    # remove name extension \n",
    "    file = splitext(_file)[0]\n",
    "    \n",
    "    # get id of vehicle\n",
    "    car_id = file.split(\"_\")[0]\n",
    "    \n",
    "    # get corresponding make\n",
    "    make = data[data.id == car_id].make.tolist()[0]\n",
    "    model = data[data.id == car_id].model.tolist()[0]\n",
    "    name = car_id\n",
    "    \n",
    "    y_train = y_train.append({'name': name, 'make':make, 'model':model}, ignore_index=True)\n",
    "    \n",
    "print(\"Files in train_files: {}\".format(len(train_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look to see which cars we actually have in the data (just first and last few)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all vehicles have 16 images each (from different angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of images per vehicle\n",
    "df = y_train.groupby(y_train.name).count()\n",
    "df[df.make != 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, the table above is empty which means that all cars have a label attached in \"metadata.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that all images have a label in 'metadata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of images and vehicles\n",
    "print(\"The dataset has got {} images of {} unique vehicles\".format(len(onlyfiles), len(y_train.name.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of a randomly chosen image and its labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_num = random.randint(0,len(onlyfiles)-1)\n",
    "image = imageio.imread(os.path.join(folder, onlyfiles[image_num]))\n",
    "print(plt.imshow(image, cmap=plt.cm.gray))\n",
    "\n",
    "# ...And corresponding labels (make and model)\n",
    "y_train.iloc[image_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop the images\n",
    "\n",
    "To make things easier on the computer, we will reduce the resolution of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the first image (all images have the same size)\n",
    "im = Image.open(os.path.join(folder, train_files[0]))\n",
    "\n",
    "# set size here\n",
    "size = 450, 450 \n",
    "print(\"Downscaling from {} to {}\".format(im.size, size))\n",
    "\n",
    "# resize\n",
    "im.thumbnail(size,Image.ANTIALIAS)\n",
    "\n",
    "# crop\n",
    "img = im.crop((0, 50, im.size[0], im.size[1]))\n",
    "\n",
    "# show cropped image\n",
    "plt.imshow(img, cmap=plt.cm.gray)\n",
    "\n",
    "# get final dimentions of all images\n",
    "image_width, image_height = img.size\n",
    "\n",
    "# set number of colour channels \n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add all images to an array\n",
    "\n",
    "Creat a large array that will store all of the (cropped) images, ready for analysis. This might take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (for training on coloured images)\n",
    "dataset = np.ndarray(shape=(len(train_files), image_height, image_width, channels), dtype=np.float32)\n",
    "\n",
    "i = 0\n",
    "for _file in train_files:\n",
    "    img = Image.open(os.path.join(folder,_file))\n",
    "    # resize\n",
    "    img.thumbnail(size,Image.ANTIALIAS)\n",
    "    # crop top of image to reduce size             \n",
    "    img = img.crop((0, 50, im.size[0], im.size[1]))\n",
    "    \n",
    "    # Convert to Numpy Array\n",
    "    x = np.array(img)  \n",
    "   \n",
    "    # Normalize\n",
    "    dataset[i] = x\n",
    "    i += 1\n",
    "    if i % 500 == 0:\n",
    "        print(\"Have added {} images to array\".format(i))\n",
    "print(\"All images to array!\")\n",
    "\n",
    "#dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recode car labels (make, model, id) into numbers instead of strings\n",
    "\n",
    "This makes it easier for the computer to understand them - it is easier for computers to distinguish between numbers than it is between sequences of characters (which are also just nubers, but big and complicated ones!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Associate each unique make with a number\n",
    "maketonumberdict = {}\n",
    "unique_make = y_train.make.unique() \n",
    "for i in range(len(unique_make)):\n",
    "    maketonumberdict[unique_make[i]] = i \n",
    "\n",
    "# Associate each unique model with a number                  \n",
    "modeltonumberdict = {}\n",
    "unique_model = y_train.model.unique() \n",
    "for i in range(len(unique_model)):\n",
    "    modeltonumberdict[unique_model[i]] = i\n",
    "\n",
    "# Associate each unique id string with a number                  \n",
    "idtonumberdict = {}\n",
    "unique_id = y_train.name.unique() \n",
    "for i in range(len(unique_id)):\n",
    "    idtonumberdict[unique_id[i]] = i\n",
    "\n",
    "    \n",
    "def makeAndModelToNumber(mydata, makedict, modeldict, iddict):\n",
    "    mydata_copy = mydata.copy() # make a copy otherwise the changes are made in both df\n",
    "    for i in range(len(mydata_copy['make'])):\n",
    "        mydata_copy.loc[i,'make'] = makedict[mydata_copy.loc[i,'make']]\n",
    "        mydata_copy.loc[i,'model'] = modeldict[mydata_copy.loc[i,'model']]\n",
    "        #mydata_copy.loc[i,'name'] = iddict[mydata_copy.loc[i,'name']]\n",
    "    return mydata_copy\n",
    "\n",
    "clean_y_train = makeAndModelToNumber(y_train, maketonumberdict, modeltonumberdict, idtonumberdict)\n",
    "\n",
    "# Drop the 'name' field as we don't care about this\n",
    "# (it's a unique name for each make-model combination)\n",
    "clean_y_train = clean_y_train.drop(\"name\", axis = 1)\n",
    "clean_y_train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "**This is the main part of the program**. In the code below, the data are divided into 'test' and 'training' sets (recall that machine learning algorithms are usually trained on one set of data, but hten tested on another set). The Tensor Flow pipline is then created as there are a number of different operations that are applied to the images (discussing all of the elements in detail would could be a whole university module on its own!).\n",
    "\n",
    "This can take around 30 mins with 5000.\n",
    "\n",
    "Begin by resetting tensorflow graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset underlying graph data\n",
    "tf.reset_default_graph()\n",
    "tf.get_default_graph().get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with tf.Graph().as_default():\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    # split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset, clean_y_train, test_size=0.2, random_state=33)\n",
    "    \n",
    "    # trainx and trainy should be numpy arrays\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Make sure the data is normalized\n",
    "    img_prep = ImagePreprocessing()\n",
    "    img_prep.add_featurewise_zero_center()\n",
    "    img_prep.add_featurewise_stdnorm()\n",
    "\n",
    "\n",
    "    ### Define our network architecture:\n",
    "    \n",
    "    # Input is a tensor: height*width images with 3 color channels (red, green and blue) \n",
    "    \n",
    "    network = input_data(shape=[None, image_height, image_width, channels],\n",
    "                         data_preprocessing=img_prep)\n",
    "    \n",
    "    # Step 1: Convolution\n",
    "    # NB: low level recognises edges and curves, high level recognises wheel shapes and logos\n",
    "    network = conv_2d(network, 5, 7, activation='relu') # number of filters: 5, filter size 7 \n",
    "    \n",
    "    # Step 2: Max pooling\n",
    "    network = max_pool_2d(network, 2) # kernel size\n",
    "    \n",
    "    # Step 3\n",
    "    network = conv_2d(network, 5, 3, activation='relu') # number of filters: 5, filter size 3 \n",
    "    \n",
    "    # Step 4: Max pooling\n",
    "    network = max_pool_2d(network, 2) # kernel size\n",
    "                        \n",
    "    # Step 5: Fully-connected 2 node neural network\n",
    "    # Looks at all images for each class and identify the high level features in common\n",
    "    network = fully_connected(network, 2, activation='relu') # number of outputs = number of classes the model has to choose from\n",
    "    \n",
    "    # Step 6: Regression\n",
    "    network = tflearn.regression(network)\n",
    "                             \n",
    "    \n",
    "    # Wrap the network in a model object\n",
    "    model = tflearn.DNN(network, tensorboard_verbose=3, tensorboard_dir =\"./tmp/tflearn_logs\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the tensor flow model has been created, but hasn't done anything yet.\n",
    "\n",
    "**Now pass the images through the model pipeline it to train it**. This is the part that can take some time. See if you can hear the computer fan start to speed up; it has a lot of work to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with session:\n",
    "    # Train the model\n",
    "    %time model.fit(X_train, y_train, validation_set= (X_test, y_test), show_metric=True, batch_size=10)\n",
    "    \n",
    "    # Save model when training is complete to a file\n",
    "    model.save(\"carclassifier.tfl\")\n",
    "    \n",
    "    print(\"Network trained and saved as carclassifier.tfl!\")\n",
    "    \n",
    "    score = model.evaluate(X_test, y_test, batch_size=10)\n",
    "    # accuracy: 0.99899999976158138\n",
    "    # loss: 210.93408\n",
    "    \n",
    "    print(\"Accuracy of the model: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the model has not performed very well, which was to be predicted considering we only provided 5000 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose a number between 0 and 1000 (size of the test set)\n",
    "i = random.randint(0,999)\n",
    "# revert type to uint8 to see image\n",
    "Image.fromarray(X_test[i].astype(np.uint8), 'RGB') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A copy is made here in case something goes wrong and we lose X_test.\n",
    "X_test_copy = X_test.copy()\n",
    "\n",
    "# revert the dictionnary for fast query\n",
    "numbertomakedict = {v: k for k, v in maketonumberdict.items()}\n",
    "numbertomodeldict = {v: k for k, v in modeltonumberdict.items()}\n",
    "\n",
    "# Model prediciton\n",
    "y_pred = model.predict_label(X_test_copy[i:i+1])\n",
    "print(\"Make: {}\".format(numbertomakedict[y_pred[0][0]]))\n",
    "print(\"Model: {}\".format(numbertomodeldict[y_pred[0][1]]))\n",
    "\n",
    "# Actual answer\n",
    "print(\"The actual answer is: {} {}\".format(numbertomakedict[y_test[i][0]], numbertomodeldict[y_test[i][1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance of model for car make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do with more powerful computers to test all of the images. Just do 75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a prediction for the first 75 vehicles\n",
    "y_pred = model.predict_label(X_test_copy[:75])\n",
    "#y_pred = model.predict_label(X_test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get only the make\n",
    "make_true = [i[0] for i in y_test[:75]]\n",
    "make_pred = [i[0] for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion_matrix(make_true, make_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Precision (total ratio of tp/(tp + fp))\n",
    "precision_score(make_true, make_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recall\n",
    "recall_score(make_true, make_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F1 score\n",
    "f1_score(make_true, make_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cohen's kappa\n",
    "cohen_kappa_score(make_true, make_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
